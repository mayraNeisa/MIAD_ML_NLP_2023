{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/albahnsen/MIAD_ML_and_NLP/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller: Construcción e implementación de árboles de decisión y métodos de ensamblaje\n",
    "\n",
    "En este taller podrá poner en práctica los sus conocimientos sobre construcción e implementación de árboles de decisión y métodos de ensamblajes. El taller está constituido por 9 puntos, 5 relacionados con árboles de decisión (parte A) y 4 con métodos de ensamblaje (parte B)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte A - Árboles de decisión\n",
    "\n",
    "En esta parte del taller se usará el conjunto de datos de Capital Bikeshare de Kaggle, donde cada observación representa el alquiler de bicicletas durante una hora y día determinado. Para más detalles puede visitar los siguientes enlaces: [datos](https://archive.ics.uci.edu/ml/machine-learning-databases/00275/Bike-Sharing-Dataset.zip), [dicccionario de datos](https://archive.ics.uci.edu/ml/datasets/Bike+Sharing+Dataset#)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos prestamo de bicicletas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación de librerías\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor, export_graphviz\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de la información de archivo .csv\n",
    "bikes = pd.read_csv('https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2023/main/datasets/bikeshare.csv', index_col='datetime', parse_dates=True)\n",
    "\n",
    "# Renombrar variable \"count\" a \"total\"\n",
    "bikes.rename(columns={'count':'total'}, inplace=True)\n",
    "\n",
    "# Crear la hora como una variable \n",
    "bikes['hour'] = bikes.index.hour\n",
    "\n",
    "# Visualización de los datos\n",
    "bikes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 1 - Análisis descriptivo\n",
    "\n",
    "Ejecute las celdas 1.1 y 1.2. A partir de los resultados realice un análisis descriptivo sobre las variables \"season\" y \"hour\", escriba sus inferencias sobre los datos. Para complementar su análisis puede usar métricas como máximo, mínimo, percentiles entre otros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 1.1\n",
    "bikes.groupby('season').total.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Celda 1.2\n",
    "bikes.groupby('hour').total.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agrupando por la estación (season) se puede ver que la mayoría de prestamos se hacen en la estación 3 que acorde a la documentación corresponde al verano. En cuanto a la hora se puede ver que en la mañana se ve un aumento de registros a las 8 y en la tarde-noche la mayor cantidad de prestamos se hacen alrededor de las 17 y 18 horas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 2 - Análisis de gráficos\n",
    "\n",
    "Primero ejecute la celda 2.1 y asegúrese de comprender el código y el resultado. Luego, en cada una de celdas 2.2 y 2.3 escriba un código que genere una gráfica del número de bicicletas rentadas promedio para cada valor de la variable \"hour\" (hora) cuando la variable \"season\" es igual a 1 (invierno) e igual a 3 (verano), respectivamente. Analice y escriba sus hallazgos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2.1 - rentas promedio para cada valor de la variable \"hour\"\n",
    "bikes.groupby('hour').total.mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con la primera gráfica se puede visualizar el promedio de prestamos a lo largo de las horas del día, permitiendo ver los picos a las 7-8 y a las 17-18 aproximadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2.2 - \"season\"=1 escriba su código y hallazgos \n",
    "bs1 = bikes[bikes['season']==1] \n",
    "bs1.groupby('hour').total.mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La estación 1 corresponde al invierno, que del punto anterior habiamos visto que corresponde a la estación con menor cantidad de prestamos. En la gráfica se puede ver un comportamiento similar al de la gráfica general de prestamos según la hora, con picos alrededor de las 8 y las 17-18 horas. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 2.3 - \"season\"=3 escriba su código y hallazgos \n",
    "bs3 = bikes[bikes['season']==3] \n",
    "bs3.groupby('hour').total.mean().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar a la gráfica anterior, se ven la misma tendencia de picos alrededor de las 8 y las 17-18 horas, pero la diferencia se ve en la cantidad de prestamos, siendo casi el doble en verano. En invierno, a las 8 se tiene alrededor de 250 prestamos mientras que en verano este numero es cercano a 400 prestamos. Así mismo, en las horas de la tarde en invierno el pico promedio de prestamos es de aproximadamente 300 mientras que en la tarde es de casi 600. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 3 - Regresión lineal\n",
    "En la celda 3 ajuste un modelo de regresión lineal a todo el conjunto de datos, utilizando \"total\" como variable de respuesta y \"season\" y \"hour\" como las únicas variables predictoras, teniendo en cuenta que la variable \"season\" es categórica. Luego, imprima los coeficientes e interprételos. ¿Cuáles son las limitaciones de la regresión lineal en este caso?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 3\n",
    "#se hace la seleccion de las variables de interés\n",
    "xTotal = bikes.filter([\"season\", \"hour\"], axis = 1)\n",
    "yTotal = bikes.filter([\"total\"], axis = 1)\n",
    "#se crean variables dummies para la codificacion de la variable categorica\n",
    "\n",
    "dummies = pd.get_dummies(xTotal['season'],prefix='season')\n",
    "xTotal = pd.concat([xTotal, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se borran las variables season y la dummie season_4 ya que si las otras dummies season son cero siginifica que la estacion es la 4 ()\n",
    "xTotal = xTotal.drop([\"season\",\"season_4\"], axis = 1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se estima el modelo\n",
    "modeloLR = LinearRegression()\n",
    "modeloLR.fit(xTotal, yTotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coeficientes\n",
    "modeloLR.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1:winter, 2:spring, 3:summer, 4:fall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al haber modelado sin la variable dummie que representaba el otoño, las interpretaciones se hacen con respecto a esta estación y los prestamos en esta estación. Así, si empezamos asumiendo que en el lugar es otoño por cada hora que pase en el día se aumentan aproximadamente 10 prestamos. Por otro lado, si asumimos una hora del día fija, si la estación es invierno la cantidad de prestamos disminuye aproximadamente en 84 con respecto al otoño, aumentaria en 16 si es primavera y en 35 si es verano.\n",
    "\n",
    "Lo anterior tiene sentido si uno piensa que en invierno sera mucho menor la cantidad de prestamos por el clima y por otro lado verano es la epoca en que mayor cantidad de prestamos se dan.\n",
    "\n",
    "En este caso teniendo en cuenta la presencia de la variable categórica se debe tener cuidado en la interpretación y validación de los resultados. Por un lado como ya se vio, la interpretación se puede hacer con las variables dummies sin embargo, para las pruebas de hipótesis se deben buscar directamente si la estación es siginificativa estadisticamente para la estimación de la cantidad de prestamos de bicicletas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 4 - Árbol de decisión manual\n",
    "En la celda 4 cree un árbol de decisiones para pronosticar la variable \"total\" iterando **manualmente** sobre las variables \"hour\" y  \"season\". El árbol debe tener al menos 6 nodos finales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se hace la seleccion de las variables de interés\n",
    "xTotal = bikes.filter([\"season\", \"hour\"], axis = 1)\n",
    "yTotal = bikes.filter([\"total\"], axis = 1)\n",
    "#se crean variables dummies para la codificacion de la variable categorica\n",
    "xTotal['season'] = pd.factorize(xTotal.season)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función que calcula el gini index\n",
    "def gini(y):\n",
    "    if y.shape[0] == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 - (y.mean()**2 + (1 - y.mean())**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función gini_imputiry para calular la ganancia de una variable predictora j dado el punto de corte k\n",
    "def gini_impurity(X_col, y, split):\n",
    "    \n",
    "    filter_l = X_col < split\n",
    "    y_l = y.loc[filter_l]\n",
    "    y_r = y.loc[~filter_l]\n",
    "    \n",
    "    n_l = y_l.shape[0]\n",
    "    n_r = y_r.shape[0]\n",
    "    \n",
    "    gini_y = gini(y)\n",
    "    gini_l = gini(y_l)\n",
    "    gini_r = gini(y_r)\n",
    "    \n",
    "    gini_impurity_ = gini_y - (n_l / (n_l + n_r) * gini_l + n_r / (n_l + n_r) * gini_r)\n",
    "    \n",
    "    return gini_impurity_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definición de la función best_split para calcular cuál es la mejor variable y punto de cortepara hacer la bifurcación del árbol\n",
    "def best_split(X, y, num_pct=10):\n",
    "    \n",
    "    features = range(X.shape[1])\n",
    "    \n",
    "    best_split = [0, 0, 0]  # j, split, gain\n",
    "    \n",
    "    # Para todas las varibles \n",
    "    for j in features:\n",
    "        \n",
    "        splits = np.percentile(X.iloc[:, j], np.arange(0, 100, 100.0 / (num_pct+1)).tolist())\n",
    "        splits = np.unique(splits)[1:]\n",
    "        \n",
    "        # Para cada partición\n",
    "        for split in splits:\n",
    "            gain = gini_impurity(X.iloc[:, j], y, split)\n",
    "                        \n",
    "            if gain > best_split[2]:\n",
    "                best_split = [j, split, gain]\n",
    "    \n",
    "    return best_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 4\n",
    "# Definición de la función tree_grow para hacer un crecimiento recursivo del árbol\n",
    "def tree_grow(X, y, level=0, min_gain=0.001, max_depth=None, num_pct=10):\n",
    "    \n",
    "    # Si solo es una observación\n",
    "    if X.shape[0] == 1:\n",
    "        tree = dict(y_pred=y.iloc[:1].values[0], y_prob=0.5, level=level, split=-1, n_samples=1, gain=0)\n",
    "        return tree\n",
    "    \n",
    "    # Calcular la mejor división\n",
    "    j, split, gain = best_split(X, y, num_pct)\n",
    "    \n",
    "    # Guardar el árbol y estimar la predicción\n",
    "    y_pred = int(y.mean() >= 0.5) \n",
    "    y_prob = (y.sum() + 1.0) / (y.shape[0] + 2.0)  # Corrección Laplace \n",
    "    \n",
    "    tree = dict(y_pred=y_pred, y_prob=y_prob, level=level, split=-1, n_samples=X.shape[0], gain=gain)\n",
    "    # Revisar el criterio de parada \n",
    "    if gain < min_gain:\n",
    "        return tree\n",
    "    if max_depth is not None:\n",
    "        if level >= max_depth:\n",
    "            return tree   \n",
    "    \n",
    "    # Continuar creando la partición\n",
    "    filter_l = X.iloc[:, j] < split\n",
    "    X_l, y_l = X.loc[filter_l], y.loc[filter_l]\n",
    "    X_r, y_r = X.loc[~filter_l], y.loc[~filter_l]\n",
    "    tree['split'] = [j, split]\n",
    "\n",
    "    # Siguiente iteración para cada partición\n",
    "    \n",
    "    tree['sl'] = tree_grow(X_l, y_l, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    tree['sr'] = tree_grow(X_r, y_r, level + 1, min_gain=min_gain, max_depth=max_depth, num_pct=num_pct)\n",
    "    \n",
    "    return tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicación de la función tree_grow\n",
    "tree_grow(xTotal, yTotal, level=0, min_gain=0.001, max_depth=6, num_pct=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 5 - Árbol de decisión con librería\n",
    "En la celda 5 entrene un árbol de decisiones con la **librería sklearn**, usando las variables predictoras \"season\" y \"hour\" y calibre los parámetros que considere conveniente para obtener un mejor desempeño. Recuerde dividir los datos en conjuntos de entrenamiento y validación para esto. Comente el desempeño del modelo con alguna métrica de desempeño de modelos de regresión y compare desempeño con el modelo del punto 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se hace la seleccion de las variables de interés\n",
    "xTotal = bikes.filter([\"season\", \"hour\"], axis = 1)\n",
    "yTotal = bikes.filter([\"total\"], axis = 1)\n",
    "#se crean variables dummies para la codificacion de la variable categorica\n",
    "xTotal['season'] = pd.factorize(xTotal.season)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se hace la particion en muestras de entrenamiento y validacion\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(xTotal, yTotal, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 5\n",
    "# Lista de valores para calibrar el criterio de parada de máxima profundidad (max_depth)\n",
    "max_depth_range = range(1, 21)\n",
    "\n",
    "# Lista para guardar los valores del RMSE para cada valor de máxima profundidad (max_depth)\n",
    "accuracy_scores = []\n",
    "\n",
    "# Importación de modelos de sklearn \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Loop para obtener el desempeño del modelo de acuerdo con la máxima profundidad\n",
    "for depth in max_depth_range:\n",
    "    # Definición del árbol de decisión usando DecisionTreeClassifier de la libreria sklearn\n",
    "    clf = DecisionTreeClassifier(max_depth=depth, random_state=1)\n",
    "    accuracy_scores.append(cross_val_score(clf, XTrain, yTrain, cv=10, scoring='accuracy').mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfica max_depth versus RMSE (error del modelo)\n",
    "plt.plot(max_depth_range, accuracy_scores)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejor accuracy (desempeño del modelo) y su correspondiente max_depth\n",
    "sorted(zip(accuracy_scores, max_depth_range))[::-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth=5 fue el mejor, se ajusta un árbol usando este valor \n",
    "clf = DecisionTreeClassifier(max_depth=5, random_state=1)\n",
    "clf.fit(XTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccion=clf.predict(XTest)\n",
    "MSE=np.average(np.square(prediccion-yTest.to_numpy().tolist()))\n",
    "print('MSE arbol con libreria:')\n",
    "print(MSE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte B - Métodos de ensamblajes\n",
    "En esta parte del taller se usará el conjunto de datos de Popularidad de Noticias Online. El objetivo es predecir si la noticia es popular o no, la popularidad está dada por la cantidad de reacciones en redes sociales. Para más detalles puede visitar el siguiente enlace: [datos](https://archive.ics.uci.edu/ml/datasets/online+news+popularity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos popularidad de noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>timedelta</th>\n",
       "      <th>n_tokens_title</th>\n",
       "      <th>n_tokens_content</th>\n",
       "      <th>n_unique_tokens</th>\n",
       "      <th>n_non_stop_words</th>\n",
       "      <th>n_non_stop_unique_tokens</th>\n",
       "      <th>num_hrefs</th>\n",
       "      <th>num_self_hrefs</th>\n",
       "      <th>num_imgs</th>\n",
       "      <th>...</th>\n",
       "      <th>min_positive_polarity</th>\n",
       "      <th>max_positive_polarity</th>\n",
       "      <th>avg_negative_polarity</th>\n",
       "      <th>min_negative_polarity</th>\n",
       "      <th>max_negative_polarity</th>\n",
       "      <th>title_subjectivity</th>\n",
       "      <th>title_sentiment_polarity</th>\n",
       "      <th>abs_title_subjectivity</th>\n",
       "      <th>abs_title_sentiment_polarity</th>\n",
       "      <th>Popular</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://mashable.com/2014/12/10/cia-torture-rep...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>188.0</td>\n",
       "      <td>0.732620</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.844262</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.80</td>\n",
       "      <td>-0.487500</td>\n",
       "      <td>-0.60</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://mashable.com/2013/10/18/bitlock-kicksta...</td>\n",
       "      <td>447.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>0.653199</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.815789</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>-0.135340</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.050000</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://mashable.com/2013/07/24/google-glass-po...</td>\n",
       "      <td>533.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.660377</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136364</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://mashable.com/2013/11/21/these-are-the-m...</td>\n",
       "      <td>413.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>781.0</td>\n",
       "      <td>0.497409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.677350</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.195701</td>\n",
       "      <td>-0.40</td>\n",
       "      <td>-0.071429</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://mashable.com/2014/02/11/parking-ticket-...</td>\n",
       "      <td>331.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.830357</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.55</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  timedelta  \\\n",
       "0  http://mashable.com/2014/12/10/cia-torture-rep...       28.0   \n",
       "1  http://mashable.com/2013/10/18/bitlock-kicksta...      447.0   \n",
       "2  http://mashable.com/2013/07/24/google-glass-po...      533.0   \n",
       "3  http://mashable.com/2013/11/21/these-are-the-m...      413.0   \n",
       "4  http://mashable.com/2014/02/11/parking-ticket-...      331.0   \n",
       "\n",
       "   n_tokens_title  n_tokens_content  n_unique_tokens  n_non_stop_words  \\\n",
       "0             9.0             188.0         0.732620               1.0   \n",
       "1             7.0             297.0         0.653199               1.0   \n",
       "2            11.0             181.0         0.660377               1.0   \n",
       "3            12.0             781.0         0.497409               1.0   \n",
       "4             8.0             177.0         0.685714               1.0   \n",
       "\n",
       "   n_non_stop_unique_tokens  num_hrefs  num_self_hrefs  num_imgs  ...  \\\n",
       "0                  0.844262        5.0             1.0       1.0  ...   \n",
       "1                  0.815789        9.0             4.0       1.0  ...   \n",
       "2                  0.775701        4.0             3.0       1.0  ...   \n",
       "3                  0.677350       10.0             3.0       1.0  ...   \n",
       "4                  0.830357        3.0             2.0       1.0  ...   \n",
       "\n",
       "   min_positive_polarity  max_positive_polarity  avg_negative_polarity  \\\n",
       "0               0.200000                   0.80              -0.487500   \n",
       "1               0.160000                   0.50              -0.135340   \n",
       "2               0.136364                   1.00               0.000000   \n",
       "3               0.100000                   1.00              -0.195701   \n",
       "4               0.100000                   0.55              -0.175000   \n",
       "\n",
       "   min_negative_polarity  max_negative_polarity  title_subjectivity  \\\n",
       "0                  -0.60              -0.250000                 0.9   \n",
       "1                  -0.40              -0.050000                 0.1   \n",
       "2                   0.00               0.000000                 0.3   \n",
       "3                  -0.40              -0.071429                 0.0   \n",
       "4                  -0.25              -0.100000                 0.0   \n",
       "\n",
       "   title_sentiment_polarity  abs_title_subjectivity  \\\n",
       "0                       0.8                     0.4   \n",
       "1                      -0.1                     0.4   \n",
       "2                       1.0                     0.2   \n",
       "3                       0.0                     0.5   \n",
       "4                       0.0                     0.5   \n",
       "\n",
       "   abs_title_sentiment_polarity  Popular  \n",
       "0                           0.8        1  \n",
       "1                           0.1        0  \n",
       "2                           1.0        0  \n",
       "3                           0.0        0  \n",
       "4                           0.0        0  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lectura de la información de archivo .csv\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2023/main/datasets/mashable.csv', index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definición variable de interes y variables predictoras\n",
    "X = df.drop(['url', 'Popular'], axis=1)\n",
    "y = df['Popular']\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# División de la muestra en set de entrenamiento y prueba\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 6 - Árbol de decisión y regresión logística\n",
    "En la celda 6 construya un árbol de decisión y una regresión logística. Para el árbol calibre al menos un parámetro y evalúe el desempeño de cada modelo usando las métricas de Accuracy y F1-Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 6\n",
    "# Lista de valores para calibrar el criterio de parada de máxima profundidad (max_depth)\n",
    "max_depth_range = range(1, 21)\n",
    "\n",
    "# Lista para guardar los valores del RMSE para cada valor de máxima profundidad (max_depth)\n",
    "accuracy_scores = []\n",
    "\n",
    "# Importación de modelos de sklearn \n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Loop para obtener el desempeño del modelo de acuerdo con la máxima profundidad\n",
    "for depth in max_depth_range:\n",
    "    # Definición del árbol de decisión usando DecisionTreeClassifier de la libreria sklearn\n",
    "    clf = DecisionTreeClassifier(max_depth=depth, random_state=1)\n",
    "    accuracy_scores.append(cross_val_score(clf, X_train, y_train, cv=10, scoring='accuracy').mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mejor accuracy (desempeño del modelo) y su correspondiente max_depth\n",
    "sorted(zip(accuracy_scores, max_depth_range))[::-1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_depth=2 fue el mejor, se ajusta un árbol usando este valor \n",
    "clfB = DecisionTreeClassifier(max_depth=2, random_state=1)\n",
    "clfB.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccionTreeB=clfB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(prediccionTreeB, y_test), metrics.accuracy_score(prediccionTreeB, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clfRegLog= LogisticRegression(random_state=0,max_iter=10000)\n",
    "clfRegLog.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccionesRegLog=clfRegLog.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediccionesRegLog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.f1_score(prediccionesRegLog, y_test), metrics.accuracy_score(prediccionesRegLog, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 7 - Votación Mayoritaria\n",
    "En la celda 7 elabore un esamble con la metodología de **Votación mayoritaria** compuesto por 300 muestras bagged para cada uno de los siguientes escenarios:\n",
    "\n",
    "-100 árboles de decisión donde max_depth tome un valor de su elección\\\n",
    "-100 árboles de decisión donde min_samples_leaf tome un valor de su elección\\\n",
    "-100 regresiones logísticas\n",
    "\n",
    "Evalúe cada uno de los tres modelos de manera independiente utilizando las métricas de Accuracy y F1-Score, luego evalúe el ensamble de modelos y compare los resultados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 7\n",
    "# Definición del modelo BaggingClassifier de la libreria sklearn\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf7a = BaggingClassifier(base_estimator=DecisionTreeClassifier(max_depth = 5), n_estimators=100, bootstrap=True,\n",
    "                        random_state=42, n_jobs=-1, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6573333333333333, 0.6573333333333333)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicción y desempeño \n",
    "clf7a.fit(X_train, y_train)\n",
    "y_pred7a = clf7a.predict(X_test)\n",
    "metrics.f1_score(y_pred7a, y_test), metrics.accuracy_score(y_pred7a, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf7b = BaggingClassifier(base_estimator=DecisionTreeClassifier(min_samples_leaf = 3), n_estimators=100, bootstrap=True,\n",
    "                        random_state=42, n_jobs=-1, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6560212907518296, 0.6553333333333333)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicción y desempeño \n",
    "clf7b.fit(X_train, y_train)\n",
    "y_pred7b = clf7b.predict(X_test)\n",
    "metrics.f1_score(y_pred7b, y_test), metrics.accuracy_score(y_pred7b, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf7c = BaggingClassifier(base_estimator=LogisticRegression(), n_estimators=100, bootstrap=True,\n",
    "                        random_state=42, n_jobs=-1, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.613099257258609, 0.618)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicción y desempeño \n",
    "clf7c.fit(X_train, y_train)\n",
    "y_pred7c = clf7c.predict(X_test)\n",
    "metrics.f1_score(y_pred7c, y_test), metrics.accuracy_score(y_pred7c, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 8 - Votación Ponderada\n",
    "En la celda 8 elabore un ensamble con la metodología de **Votación ponderada** compuesto por 300 muestras bagged para los mismos tres escenarios del punto 7. Evalúe los modelos utilizando las métricas de Accuracy y F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6494915254237288, 0.6553333333333333)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Celda 8\n",
    "# Obtención de los pesos alpha de cada modelo de acuerdo al error OOB para el primer caso\n",
    "errors = np.zeros(clf7a.n_estimators)\n",
    "y_pred_all_ = np.zeros((X_test.shape[0], clf7a.n_estimators))\n",
    "\n",
    "for i in range(clf7a.n_estimators):\n",
    "    oob_sample = ~clf7a.estimators_samples_[i]\n",
    "    y_pred_ = clf7a.estimators_[i].predict(X_train.values[oob_sample])\n",
    "    errors[i] = metrics.accuracy_score(y_pred_, y_train.values[oob_sample])\n",
    "    y_pred_all_[:, i] = clf7a.estimators_[i].predict(X_test)\n",
    "    \n",
    "alpha = (1 - errors) / (1 - errors).sum()\n",
    "y_pred8a = (np.sum(y_pred_all_ * alpha, axis=1) >= 0.5).astype(np.int)\n",
    "\n",
    "\n",
    "metrics.f1_score(y_pred8a, y_test), metrics.accuracy_score(y_pred8a, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punto 9 - Comparación y análisis de resultados\n",
    "En la celda 9 comente sobre los resultados obtenidos con las metodologías usadas en los puntos 7 y 8, compare los resultados y enuncie posibles ventajas o desventajas de cada una de ellas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Celda 9"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
